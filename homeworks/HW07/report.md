# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9) (включая `sample_id`)
- Признаки: только числовые (8 признаков) + `sample_id` как идентификатор
- Пропуски: нет
- "Подлости" датасета: разные шкалы числовых признаков + шумовые признаки (без масштабирования качество “едет”)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4) (включая `sample_id`)
- Признаки: только числовые (3 признака) + `sample_id` как идентификатор
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров + шумовой признак (`z_noise`), из-за чего KMeans часто даёт неидеальное разбиение

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 33) (включая `sample_id`)
- Признаки: 30 числовых + 2 категориальных (`cat_a`, `cat_b`) + `sample_id` как идентификатор
- Пропуски: есть (примерно ~2% в числовых `n01..n30`)
- "Подлости" датасета: высокая размерность + категориальные признаки + пропуски (нужны imputer + encoding + scaling)

## 2. Protocol

- Препроцессинг:
  - Dataset-01/02: `StandardScaler` для всех числовых признаков (через `ColumnTransformer`).
  - Dataset-04:
    - числовые: `SimpleImputer(strategy="mean")` + `StandardScaler`,
    - категориальные: `SimpleImputer(strategy="most_frequent")` + `OneHotEncoder(handle_unknown="ignore")`,
    - объединение через `ColumnTransformer`.
- Поиск гиперпараметров:
  - KMeans: перебор `k` в диапазоне `2..20`, фиксировали `random_state` и `n_init=10`. В качестве основной эвристики выбора использовали максимум `silhouette` среди валидных значений.
  - Второй метод:
    - Dataset-01 и Dataset-04: DBSCAN, перебор `eps` и `min_samples` по небольшой сетке; дополнительно строили k-distance plot как эвристику для `eps`.
    - Dataset-02: AgglomerativeClustering, перебор `k=2..20` и `linkage ∈ {ward, complete, average}`.
- Метрики: считали `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`.
  - Для DBSCAN: при наличии шума (`label=-1`) метрики считали **только на non-noise точках**, и отдельно фиксировали долю шума (`noise_ratio`).
- Визуализация:
  - Для каждого датасета: PCA(2D) scatter с раскраской по лучшему разбиению.
  - Доп. графики подбора: `silhouette vs k` (KMeans), k-distance plot / сравнение параметров (DBSCAN), и `silhouette vs k` для выбранного `linkage` (Agglomerative).

## 3. Models

- Dataset-01:
  - KMeans: подбирали `k` (2..20), фиксировали `random_state`, `n_init=10`.
  - DBSCAN: подбирали `eps` и `min_samples`, анализировали `noise_ratio`.
- Dataset-02:
  - KMeans: подбирали `k` (2..20), фиксировали `random_state`, `n_init=10`.
  - AgglomerativeClustering: подбирали `k` (2..20) и `linkage` (ward/complete/average).
- Dataset-04:
  - KMeans: подбирали `k` (2..20), фиксировали `random_state`, `n_init=10`.
  - DBSCAN: подбирали `eps` и `min_samples`, анализировали `noise_ratio`.

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans**, `k=2`
- Метрики (silhouette / DB / CH):
  - silhouette = **0.522**
  - Davies-Bouldin = **0.685**
  - Calinski-Harabasz = **11786.955**
- Если был DBSCAN: метрики считались по non-noise, доля шума была ~**9.2%**, silhouette ~**0.399** (хуже KMeans)
- Коротко: после масштабирования KMeans нашёл 2 крупных кластера с хорошей разделимостью. По профилям признаков кластеры сильнее всего различаются по `f04` (разница средних ≈ **117.99**), далее `f02` (≈ **51.24**), `f06` (≈ **35.37**), `f01` (≈ **24.96**), `f05` (≈ **12.83**). Это согласуется с идеей, что без scaling доминирующие шкалы “утащили бы” distance.

### 4.2 Dataset B

- Лучший метод и параметры: **AgglomerativeClustering**, `k=2`, `linkage="average"`
- Метрики (silhouette / DB / CH):
  - silhouette = **0.420**
  - Davies-Bouldin = **0.879**
  - Calinski-Harabasz = **395.483**
- Коротко: Dataset-02 содержит нелинейную структуру, поэтому KMeans (лучший silhouette ≈ **0.307** при `k=2`) уступил иерархической кластеризации. Итоговые два кластера имеют сильно несбалансированные размеры: **7902** и **98** объектов (возможный эффект выбросов/редкой “ветви”), что также объясняет, почему KMeans и метрики ведут себя неоднозначно на этом датасете.

### 4.3 Dataset C

- Лучший метод и параметры: **DBSCAN**, `eps=2.0`, `min_samples=10`
- Метрики (silhouette / DB / CH) (считались по non-noise точкам):
  - silhouette = **0.508**
  - Davies-Bouldin = **0.823**
  - Calinski-Harabasz = **3867.243**
- Если был DBSCAN:
  - доля шума ≈ **49.23%** (4923 / 10000),
  - non-noise точек: **5077 / 10000**,
  - число кластеров (non-noise) = **6**.
- Коротко: высокая размерность + пропуски + категориальные признаки требуют аккуратного препроцессинга (impute + scaling + OHE). DBSCAN оказался уместен тем, что явно отделил почти половину точек как noise/выбросы, а на “чистых” точках дал лучшее качество по silhouette, чем KMeans (best KMeans: silhouette ≈ **0.448** при `k=5`). Дополнительно видно, что кластеры хорошо коррелируют с комбинациями категорий: например, в кластере 0 доминирует `(cat_a=C, cat_b=Y)` (**~76.8%** внутри кластера), в кластере 1 — `(E,U)` (**~81.9%**), в кластере 2 — `(A,W)` (**~88.9%**), в кластере 3 — `(D,Z)` (**~90.3%**), в кластере 4 — `(B,X)` (**~95.6%**), в кластере 5 — `(F,V)` (**~98.8%**).

## 5. Analysis

### 5.1 Сравнение алгоритмов 

- KMeans хорошо работает, когда кластеры близки к “сферическим” и корректно масштабированы (Dataset-01). Здесь выбор `k=2` дал высокие значения silhouette и CH при низком DB.
- На нелинейных/сложных структурах KMeans часто проигрывает, потому что оптимизирует разделение относительно центроидов и “режет” пространство не по реальной форме кластеров (Dataset-02).
- AgglomerativeClustering с `average linkage` оказался более гибким на Dataset-02 и дал заметно лучший silhouette, чем KMeans, что согласуется с тем, что метод не предполагает строго “шарообразную” геометрию.
- DBSCAN полезен, когда есть шум/выбросы или неоднородная плотность: он может выделять “непринадлежность” к кластерам (label = -1). Это особенно оказалось релевантно на Dataset-04, где значимая часть точек уходит в noise.
- Самое сильное влияние на качество давали: масштабирование (Dataset-01), форма кластеров/нелинейность (Dataset-02), а также комбинация высокой размерности + пропусков + категориальных признаков (Dataset-04).

### 5.2 Устойчивость 

- Проверка устойчивости делалась на **Dataset-01** для KMeans: 5 запусков с разными `random_state`, сравнение разбиений через **ARI** относительно базового решения.
- Результат: `ARI vs base = 1.0` для всех seed `{1, 42, 100, 123, 999}`.
- Вывод: решение полностью устойчиво к смене инициализации (в данном датасете оптимум, судя по всему, “сильный”, и разные инициализации приходят к одному и тому же разбиению).

### 5.3 Интерпретация кластеров

- Интерпретация делалась через сравнение профилей признаков внутри кластеров:
  - Dataset-01: кластеры различаются в основном по нескольким “сильным” признакам (`f04`, `f02`, `f06`, `f01`, `f05`), что видно по разнице средних (самая большая по `f04` ≈ 118).
  - Dataset-02: разбиение на 2 кластера сильно несбалансированно по размеру (7902 vs 98), что похоже на “малую группу”/выбросы; из-за этого интерпретация по средним ограничена и зависит от структуры в (x1, x2).
  - Dataset-04: кластеры хорошо объясняются сочетаниями категориальных признаков (каждый кластер почти “моно категориален”), а DBSCAN дополнительно отделяет большую долю точек как noise, что выглядит разумно при высокой размерности и наличии пропусков/выбросов.

## 6. Conclusion

- Масштабирование критично для distance-based методов: без него признаки в больших шкалах доминируют и “ломают” геометрию расстояний.
- Внутренние метрики (silhouette/DB/CH) полезны для подбора параметров, но их нужно интерпретировать вместе и с пониманием предположений метода.
- KMeans лучше всего работает при “шарообразных” кластерах и может ошибаться на нелинейных структурах.
- AgglomerativeClustering (особенно average linkage) может быть гибче на сложных формах кластеров.
- DBSCAN удобен, когда есть шум/выбросы: он явно помечает noise, но чувствителен к `eps/min_samples`.
- Для DBSCAN важно честно учитывать шум: явно выводить его долю и считать метрики по non-noise (или объяснять другой выбор).
- PCA(2D) — полезная визуальная проверка структуры, но это иллюстрация, а не “доказательство качества”.
- Проверка устойчивости (многократные запуски + ARI) помогает понять, насколько решение воспроизводимо.